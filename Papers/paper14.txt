119

on the influence on learning of student compliance with
prompts fostering self-regulated learning
sébastien lallé

cristina conati

roger azevedo

university of british columbia
2366 main mall
vancouver, bc v6t1z4, canada

university of british columbia
2366 main mall
vancouver, bc v6t1z4, canada

north carolina state university
106 caldwell hall
raleigh, nc 27695-8101, usa

lalles@cs.ubc.ca

conati@cs.ubc.ca

razeved@ncsu.edu

nicholas mudrick

michelle taub

north carolina state university
106 caldwell hall
raleigh, nc 27695-8101, usa

north carolina state university
106 caldwell hall
raleigh, nc 27695-8101, usa

nvmudric@ncsu.edu

mtaub@ncsu.edu

abstract
in this paper, we investigate the relationship between students’
learning gains and their compliance with prompts fostering selfregulated learning (srl) during interaction with metatutor, a
hypermedia-based intelligent tutoring systems (its). when possible, we evaluate compliance from student explicit answers on
whether they want to follow the prompts, when such answers are
not available, we mine several student behaviors related to prompt
compliance. these behaviors are derived from students’ eyetracking and interaction data (e.g., time spent on a learning page,
number of gaze fixations on that page). our results reveal that
compliance with some, but not all srl prompts provided by
metatutor do influence learning. these results contribute to gain
a better understanding of how students benefit from srl prompts,
and provides insights on how to further improve their effectiveness. for instance, prompts that do improve learning when followed could be the focus of adaptation designed to foster compliance for those students who would disregard them otherwise.
conversely, prompts that do not improve learning when followed
could be improved based on further investigations to understand
the reason for their lack of effectiveness

keywords
intelligent tutoring systems; self-regulated learning; scaffolding;
compliance with prompts; learning gains; eye tracking; linear
regression; hypermedia

1. introduction
there is extensive evidence that the effectiveness of intelligent
tutoring systems (its) is influenced by how well students can
regulate their learning, e.g., [13, 22]. current research has shown
that scaffolding self-regulated learning (srl) strategies such as
setting learning goals or assessing progress through the learning
content can improve learning outcomes with an its, e.g., [1, 10,
22]. in particular, one of the most common approaches to scaffold
srl is to deliver prompts designed to guide students in applying
specific srl strategies as needed [22]. previous work has focused
on assessing the general effectiveness of such srl prompts, for
instance by comparing learning outcomes of students working
with versions of the same its with and without the prompts. (e.g.,
[1, 19, 21]). other work has investigated the extent to which
students comply with the overall set of prompts generated by an
its [16, 21]. however, there has been no reported study on the

relationship between compliance with specific srl prompts and
learning outcomes. in this paper, we aim to fill this gap. specifically, we explore the impact of student compliance with srl
prompts on learning gains with metatutor, an its designed to
scaffold student srl processes while learning about topics of the
human circulatory system [1].
our results show that student learning is influenced by compliance with some, but not all, of the srl prompts delivered by
metatutor. overall, we found a positive impact on learning for
compliance with prompts fostering learning strategies (revising a
summary, reviewing notes), or planning processes (setting new
learning goals). on the other hand, we found no impact on learning with prompts related to metacognitive monitoring processes
(e.g., prompts to stay on or move away from the current page
depending on student performance on a quiz on that page). having information on the efficacy of each specific prompt in a its is
important to guide further research on how to improve prompts
that do not seem to improve learning when students follow them.
furthermore, prompts that foster learning when followed can
become the focus of adaptive interventions designed to improve
compliance for those students who would disregard these prompts
if left to their own device.
the paper also provides initial insights into prompts design issues
that affect how easy it is to evaluate compliance. in metatutor,
some prompts explicitly asked students whether they wanted to
follow the prompt, and then provided suitable affordance to accommodate a positive reply. compliance with these prompts is
easy to assess, but the additional interactions that they require
might not always be possible, or might even be intrusive for some
students. other prompts did not require any specific response
from the students. thus, such prompts are in less danger of being
intrusive, and provide for a more open-ended interaction. on the
other hand, assessing compliance with these prompts is not trivial,
because there is no clear definition of what compliance means.
for example, one of the metatutor prompts asks students to reread the current metatutor content page, but there is no obvious
way to map this rather generic suggestion to a specific desired
behavior (e.g., spend a specific amount of time on the page, read a
specific number of words). we addressed this problem by running
linear models to correlate a variety of student behaviors related to
prompt compliance with learning. the behaviours we mined are
based on both action and eye-tracking data (e.g., time spent on
that page, gaze fixations on the content of the page), and our120

figure. 1. screenshot of metatutor.
results provide initial evidence that combining these two data
sources can help to evaluate compliance. thus, our findings represent a step toward research on how to evaluate compliance with
prompts, both for the type of off line analysis presented in this
paper, as well as for the real-time detection of compliance necessary if we want to have itss that adaptively help students follow
prompts as needed.
the remainder of the paper starts with an overview of related
work, followed by a description of metatutor and the study that
generated the dataset we used for this research. next, we illustrate
how we mined data to evaluate compliance with metatutor’s
prompts, the statistical analysis we conducted, and our results.

2. related work
there has been extensive work on assessing the effectiveness of
scaffolding designed to support learning with itss. scaffolding
can include prompts or hints (i.e., interventions that guide the
student in the right direction), feedback (evaluation of students
answers, behavior or strategies), or demonstration (e.g., worked
examples showing expert behavior) [22, 23]. such scaffolding can
be domain-specific to support the acquisition of domain-specific
knowledge, or targeting domain-independent, meta-cognitive
learning processes such as processes for self-regulated learning
(srl). there is extensive evidence that both domain-specific
scaffolding (e.g., [3, 12, 18, 20]) and meta-cognitive scaffolding
(e.g., [2, 10, 11, 21]) can improve the effectiveness of its. for
example, domain-specific hints that explain how to solve the
current problem step have been shown to improve skill acquisition in a variety of domains such as mathematics [20] and reading
[3, 12]. at the meta-cognitive level, roll et al. [21] tracked
suboptimal help-seeking patterns (e.g., overuse of help) to deliver
prompts and feedback on how to effectively use help. prompts
and feedback designed to help construct self-explanations during
reading [10] or solving scientific problems [11] have been found

to positively influence learning. azevedo et al. [2] showed that
srl prompts and feedback effectively foster efficient use of srl
strategies while learning about biology.
research has also examined student compliance with srl
prompts in its [5, 16]. kardan and conati [16] examined the
benefit of providing a variety of prompts designed to help students progress within an interactive learning simulation. overall
they found that students largely complied with the prompts and
that providing these prompts improved learning gains. however,
they did not explore whether and how compliance with specific
prompts influence learning outcomes, and which prompts are the
most effective. bouchet et al. [5] adapted the frequency of prompt
delivery in metatutor based on whether students previously complied with prompts of the same type. however, their analysis
uncovered no influence of such adaptive prompting strategy on
learning gains. we extend the aforementioned work on prompt
compliance by showing how learning gains are impacted by compliance with some, but not all srl prompts in metatutor. furthermore, whereas previous solely used interaction data to evaluate compliance, we also leverage eye-tracking data when compliance cannot be inferred directly from students’ answers or actions
(e.g., compliance with the prompts of reading a text further).
eye-tracking has been used in its to model a variety of students
traits and behavior, e.g., emotions [14], learning outcomes [15],
metacognitive behavior [7], or mind wandering [4]. eye tracking
has also been used to capture students attention to prompts [6, 8]
and to pedagogical agents [17]. conati et al. [6] leveraged gaze
data to detect whether students processed domain-specific textual
prompts in an educational game for math, and found that reading
the prompts more extensively improved game performance. lallé
et al. [17] used gaze data to capture student visual attention to
pedagogical agents in metatutor, and found that student learning
gains are significantly influenced by specific metrics for visual
attention (fixation rate, longest fixation). eye-tracking has also121

been used to add real-time adaptive prompts to guru, an agentbased its for learning biology [9]. in that work, audible prompts
designed to reorient student attention towards the screen were
triggered if a student had not looked at the screen for more than 5s
while guru was providing scaffolding. this research showed that
this gaze-reactive feedback can improve learning with guru. in
our work, we mine eye-tracking data to evaluate compliance with
specific srl prompts, and examine whether and how compliance
with such srl prompts influences learning gains.

3. metatutor
metatutor [1] is a hypermedia-based its containing multiple
pages of content about the circulatory system, as well as mechanisms to help students self-regulating their learning with the assistance of multiple speaking pedagogical agents (pas). when working with metatutor, students are given the overall goal of learning
as much as they can about the human circulatory system. the
main interface of metatutor (see fig. 1) includes a table of contents (fig. 1a), the text of the current content page (fig.1b), a
miniature image allowing the student to display a diagram along
with the text (fig. 1c), the current goals and subgoals to learn
about (fig. 1e), a timer indicating how much time remains in the
learning session (fig. 1f), and an srl palette (fig. 1d). this
palette is designed to scaffold students self-regulatory processes
by providing buttons they can select to initiate specific srl activities (e.g., making a summary, taking a quiz, setting subgoals).
further srl scaffolding is provided by three pas in the form of
feedback on student performance on these srl activities (e.g.,
performance on quiz or on the quality of their summaries), as well
as prompts designed to guide these activities as needed. the pas
deliver these prompts based on student behavior (e.g., time spent
on page, number of pages visited).
specifically, pam the planner prompts planning processes primarily at the beginning of the learning session by suggesting to
add a new subgoal and, if needed, which one to choose (e.g., path
of blood flow, heart components). mary the monitor scaffolds
students’ metacognitive monitoring processes by making them
take quizzes on the target material when they appear to be ready
for them. based on quiz outcomes, mary prompts students to
evaluate the relevance of the current content and subgoal to their
knowledge, and suggests how to move through the available material and sub goals accordingly. sam the strategizer prompts students to apply the learning strategies consisting of summarizing
the content studied so far or reviewing notes they have taken on
the content1.
all pas provide audible assistance through the use of a text-tospeech engine (nuance). the pas are visually rendered using
haptek virtual characters, which generate idle movements when
the pas are not speaking (subtle, gradual head and eye movements), as well as lip movements during speech.

4. user study
the data used for the analysis presented in this paper were collected via a user study designed to gain a general understanding of
how students learn with metatutor [1]. the study included the
collection of a variety of multi-channel trace data (e.g., eye track-

1

more details about the design of the agents can be found in [1].

ing, log files, physiological sensors). in this paper, we focus on
using interaction and eye-tracking data to track compliance with
the srl prompts provided by metatutor, and study the relationship among compliance with the prompts and learning gains.
twenty-eight college students participated in the study, which
consisted of two sessions conducted on separate days. during the
first session, lasting approximately 30-60 minutes, students were
administered several questionnaires, including a 30-item pretest to
assess their knowledge of the circulatory system. during the second session lasting approximately three hours, students first underwent a calibration phase with the eye tracker (smi red 250)
as well as a training session on metatutor. each student was then
given 90 minutes to interact with the system. finally, students
completed a posttest analogous to the pretest, followed by a series
of questionnaires about their experience with metatutor.

5. data analysis
5.1 evaluating compliance with prompts
in our analysis we categorize prompts into two types based on
how compliance can be evaluated. the first type includes prompts
for which compliance can be explicitly assessed from students
subsequent responses (explicit compliance prompts); the second
type includes prompts for which compliance needs to be inferred
by mining a variety of behaviors (inferred compliance prompts).
explicit compliance prompts are those that:
 require students to answer “yes” or “no” (using a dialogue
panel that becomes active at the bottom of the display). if students answers yes, the only action they can perform in the
metatutor interface is the one they agreed upon (e.g., adding a
specific subgoal suggested by the agent, making or revising a
summary, moving to a previously added subgoal or staying on
the current one)2.
 require students to take a specific action within a specific time
frame (i.e., open the diagram while they are on the current page,
and review notes by the end of the learning session).
table 1 lists the explicit compliance prompts considered in this
analysis.
inferred compliance prompts are those for which the pas do not
force students to provide an explicit answer. specifically, after the
agent utters one of these prompts, the student simply clicks on
“continue” in the same dialogue panel, and can either ignore the
prompted action, or comply at some point. these prompts (listed
in table 2) include all prompts related to staying on or moving
away from the current page, as well as initiating the action of
adding a new subgoal.

5.2 statistical analysis
our analysis aims to investigate if and how compliance with
metatutor’s srl prompts influence learning. the variable we

2

for the “stay on current subgoal” prompt, students are not forced
to comply after answering “yes”, but we have listed it in this
category because student are still required to explicitly answer
“yes” or “no” to the pas as for whether they want to follow the
prompt or not.122

table 1. list of explicit compliance prompts provided in metatutor (grouped by type of prompted srl processes).
prompt label

description

prompts for

suggest subgoal recommend possible subgoals to learn about while the students is adding new subgoal.

planning processes

moving to next
subgoal

recommend moving on to another subgoal when the student did well on a quiz related to
the current subgoal.

stay on subgoal

recommend to learn more about the current subgoal when the student did not do well
enough on a quiz related to that subgoal.

open diagram

recommend opening the diagram when it is relevant to the current subgoal.

summarize

recommend making a summary of the current page when the student has spent enough
time on that page.

revise summary

recommend revising the summary submitted by the student when there are issues with the
learning strategies
summary (e.g., the summary is too long or too short).

review notes

recommend reviewing notes taken on the learning content when approaching from the
end of the session.

metacognitive monitoring processes

table 2. list of inferred compliance prompts provided in metatutor (grouped by type of prompted srl processes).
prompt label

description

prompts for

add subgoal

recommend adding a new subgoal to learn about when a student has no active subgoal.

move to next
page

recommend moving on to another page when the student did well on a quiz related to the
current page.
metacognitive monitorrecommend staying on the current page when the student did not well enough on a quiz ing processes
related to that page.

stay on page

adopted to measure learning in our analysis is proportional learning gain, defined as:

planning processes

table 4 shows the compliance rate averaged across students for
each of the seven explicit compliance prompts in metatutor, and
the number of prompts delivered.
table 4. descriptive statistics of the number of explicit compliance prompts delivered, as well as on compliance rate.

table 3 reports statistics for pre- and post-test scores, as well as
for the corresponding learning gains.3
table 3. descriptive statistics for pretest, posttest, and
learning gain.
measures of learning
pretest
posttest
proportional learning gain

m
18.6
21.4
15.3

sd
4.2
4
50.2

median
19
21
20

we conducted two separate analyses for explicit and inferred
compliance prompts, described next.
explicit compliance prompts. since compliance is directly
observed in the data for explicit compliance prompts (listed in
table 2), we computed a compliance rate for each of these
prompts as follow:

3

the increase from pretest to post-test is statistically significant
indicating that metatutor is overall effective at fostering learning, as further discussed in [1].

prompt
suggest subgoal
move next subgoal
stay on subgoal
open diagram
summarize
revise summary
review notes

total number of
prompts delivered
60
25
44
77
105
59
28

compliance rate
mean (sd)
.90 (.25)
.85 (.34)
.27 (.37)
.21 (.32)
.32 (.41)
.76 (.37)
.46 (.51)

to investigate the impact of compliance with explicit compliance
prompts on learning, we ran a multiple linear regression model
with proportional learning gain as the dependent variable, as
well as the compliance rate for each of the seven explicit compliance prompts, and the total number of prompts received as the
factors. for post-hoc analysis we ran pairwise t-test comparisons,
and p-values were adjusted with the holm-bonferroni approach to
account for multiple comparisons.
inferred compliance prompts. as stated above, for inferred
compliance prompts (listed in table 5), students are not forced to
explicitly accept or ignore the prompt. this means that compliance with those prompts has to be assessed from student behaviors following the prompts. one approach we considered was to
make this assessment binary, as we did for explicit compliance
prompts, by establishing thresholds for relevant behaviors. for
instance, compliance with the prompt to re-read the current page
could be assessed to be true if the student stays on the page for a
fixed number of seconds after receiving this prompts. however, it123

is difficult to fix these thresholds in an informed manner, as they
may depend on the student (e.g., on a student’s readings speed,
existing understanding of the page, etc.), and on the object of the
prompt (e.g., on the length or difficulty of the page to be re-read).
it is also difficult to decide which specific behaviors should be
considered for compliance, as several might be relevant (e.g., time
spent on a page, specific attention patterns on a page).
thus, for the subsequent analysis, we avoided committing to
specific thresholds and behaviors, and we opted instead for performing regression analyses to try to relate multiple relevant compliance behaviors to learning.
we started by building data windows that capture student data
from the delivery of each inferred compliance prompt in table 2,
to the following actions:
 “moving to another page” for the move to next page and stay
on page prompts;
 “adding a new subgoal” for the add new subgoal prompt.
we used these data windows to derive three behavioral measures
related to compliance:
 window length, capturing how long students spent before moving on to another page or adding a new subgoal;
 number of fixations4 made on metatutor’s learning content
(text and diagram), as captured by eye tracking. we use this
measure to understand whether students read the page and/or
processed the diagram;
 number of srl strategies initiated by the student by pressing
the corresponding buttons in the srl palette (see fig. 1 d).
higher values of these measures (i.e., long windows, high number
of fixations on the page and high number of srl strategies used)
are possible indicators that the student is processing the current
page, e.g., the student is thinking about or reading the content (as
captured by the length of the data window and number of fixations on the page), or using srl strategies on the current page.
thus, we hypothesized that higher values of these measures could
reveal compliance with stay on page prompts, whereas lower
values could reveal compliance with prompts instructing students
to move on. similarly, because prompts to add a subgoal requires
moving on from the learning content to actually add a subgoal, we
expected a short window, a small number of fixations on the page,
and a small number of srl strategies to indicate compliance.
it should be noted that we could have generated other eyetracking measures, such as fixation duration on the text or the
number of transitions from the text to other components of the
metatutor’s interface. however, because valid eye-tracking data
were collected for only 16 students out of the 28 who participated
in the study, resulting in a rather small dataset, we focused on the
most promising behavioral measures that could be related to compliance, as a proof of concept. table 5 shows the amount of inferred compliance prompts delivered to those 16 students.

table 5. number of inferred prompts delivered.
prompt
add a subgoal
stay on page
move to next page

we leveraged the three aforementioned measures of student behavior to investigate if complying with inferred compliance
prompts influences learning, and if so, how. specifically, for each
of the three inferred compliance prompts, we ran a multiple linear
regression model with proportional learning gain as the dependent variable, as well as the window length, number of srl strategies performed, and number of fixations on the learning content
as the factors. as done for explicit compliance prompts, we used
pairwise t-test comparisons for post-hoc analysis, and all p-values
were adjusted with the holm-bonferroni approach.

6. results

we describe below the significant5 effects found in our analysis,
first for explicit compliance prompts, and second for inferred
compliance prompts.

6.1 effects for explicit compliance prompts
our statistical analysis uncovered significant main effects of compliance rate for three explicit compliance prompts:
 revise summary (f1,20 = 6.17, p=.02, ηp2 =.15), shown fig. 2a.
 review notes (f1,20 = 7.43, p=.013, ηp2 =.16), shown fig. 2b.
 suggest subgoal (f1,20 = 11.4, p=.003, ηp2=.27), shown fig. 2c.
these three main effects and related pairwise comparisons all
reveal that students learned more when they complied more with
these prompts than when complying less.
these results for revise summary and review notes are consistent
with previous findings showing these learning strategies can be
beneficial for learning [17, 22, 24], and extend them by showing
that prompting these strategies is effective when students comply
with the prompts. notably, we found a significant effect for
prompts to revise summary, but not for prompts to summarize.
this indicates that solely prompting to summarize is not enough
to improve learning, and that guiding the students through the
process of making a good summary is necessary. results for suggest subgoal indicate that recommending a particular learning
subgoal is useful, possibly because it is difficult for students to
choose good subgoals by themselves.
these results suggest to examine ways to improve compliance
with prompts to revise summary, review notes and suggest subgoal, since our analysis reveals that not complying with them
hinders learning. for instance, metatutor could foster compliance
with these prompts by explaining how they can help the students,
or conversely force the students to follow these prompts.

5
4

fixation is defined as gaze maintained at one point on the screen
for at least 80ms.

total number of
prompts delivered
34
117
326

we report statistical significance at the 0.05 level throughout
this paper, and effect sizes as small for ηp2 ≥ 0.02, medium for
ηp2 ≥ 0.13, and large for ηp2 ≥ 0.26.124

a. main effect of compliance rate with “revise summary”.

b. main effect of compliance rate with “review notes”.

c. main effect of compliance rate with “suggest subgoal”.

d. main effect of fixation on page after reception of “add
subgoal”.

figure 2. main effects found in this analysis, for explicit compliance prompts (charts a, b, c) and inferred conpliance prompts
(chart d). error bars show 95% confidence interval.
we found no significant effects and small effect sizes (see appendix a) for the four remaining prompts, namely summarize, stay
on subgoal or move to next subgoal, and open the diagram.
these results indicate it is important to study the effectiveness of
srl prompts individually, to identify those for which compliance
does not improve learning. based on these findings, it is justified
to further investigate why complying with these prompts is not
beneficial for learning in metatutor, and revise the prompts accordingly. for example, it might be due to the nature of the
prompts, their timing, their frequency, their wording, and so forth.

6.2 effects for inferred compliance prompts
we found a main effect of fixation on learning content for the
“add subgoal” prompts (f1,3 = 13, p = .03, ηp2 = .29), shown in
fig. 2d. this effect and related pairwise comparisons reveal that
students learned more when they fixate more on the current page
than when fixating less. since students were instructed to add a
new subgoal rather than process the current page, this finding
suggests that complying with this prompt might not be effective
for learning with metatutor, possibly because of the timing of
this prompt, its frequency or its wording. although only seven
students with valid gaze data received this prompt, the effect size
is large, suggesting it is worth conducting further analysis to ascertain whether and why complying with this prompt is not beneficial for learning.

we found no effects and small effect sizes (see appendix b) for
the other inferred compliance prompts, namely stay on page and
move to next page, two prompts related to metacognitive monitoring processes. we cannot make final conclusions on the pedagogical effectiveness on these prompts based on these results, because
the dataset is not large and for this reason we did not include in
the analysis other features that could indicate compliance (for
example other eye-tracking measures such as fixation duration on
text or gaze transitions from the text to other components of
metatutor). however, it should be noted that we also found no
effect for the explicit compliance prompts that foster metacognitive monitoring processes (stay on subgoal, move to next subgoal,
and open the diagram, see previous section). this lack of effect
for all prompts fostering metacognitive monitoring, even when
compliance is explicitly assessed, suggests that these prompts are
not beneficial for learning with metatutor. this could be due to
the way these prompts are currently implemented in metatutor
(e.g., their wording, timing delivery or frequency), or to the nature
or the prompts itself. our results nonetheless justify to run further
analysis to ascertain whether (and why) prompts fostering metacognitive monitoring are not effective, and revise them as needed.

7. conclusion
in this research we investigated the relationship between compliance with prompts designed to support the use of self-regulated
learning (srl) processes and learning gains while learning about125

the human circulatory system with metatutor. we identified two
approaches to evaluate compliance to metatutor’s prompts:
(i) assess compliance from students’ subsequent response to the
prompts when students are forced to express compliance (e.g., by
answering “yes” or “no” to a prompt);
(ii) run linear models to examine the influence on learning of a
variety of student behaviors related to prompt compliance, when
compliance is not elicited by metatutor. the behaviors we mined
are based on both interface and eye-tracking data (e.g., time spent
on that page, gaze fixations on the content of the page).
our results revealed that student learning gains are influenced by
compliance with some, but not all srl prompts provided by
metatutor. specifically, we found a positive influence on learning
for prompts that foster learning strategies (revise a summary and
review notes) as well as prompts that recommend setting a specific learning subgoal. based on these findings, it is worth exploring
ways to improve compliance with these prompts. in particular, in
future research we plan to examine whether forcing students to
comply with these prompts or providing detailed explanations on
how the prompted srl strategies can be useful can improve
learning.
we found that compliance with the other metatutor’s prompts
studied in this analysis does not improve learning. this finding
reveals that assessing compliance to srl prompts individually is
useful to identify prompts that may not be effective at supporting
learning. in particular, we found no results for all prompts related
to metacognitive monitoring processes (e.g., staying on/moving
away from the current page), suggesting to examine further why
complying with these prompts do not influence learning with
metatutor. for example, it could be due to their timing and frequency, their wording, their nature, and so forth.
in this paper we also addressed the challenge of evaluating compliance with rather open-ended prompts for which there is no
clear definition of compliance. specifically we ran a linear regression analysis to relate relevant compliance behaviors to learning.
such behaviors were derived from a combination of student interaction and eye-tracking data after receipt of a prompt (e.g., time
spent and amount of gaze fixations on a page can reveal compliance with prompt to read that page). preliminary results show that
such interaction-based and eye-tracking-based measures can help
evaluate compliance. in future research, we plan to investigate
further behavioral measures relevant to assessing compliance,
such as tracking eye gaze patterns on the different components of
metatutor as well as transitions between those components.
lastly, we plan to investigate the possibility of detecting in real
time compliance with srl prompts for which we found a positive
effect on learning, using eye-tracking and interaction data. such
real-time detection could inform the design of adaptive prompts to
foster compliance for those students who might otherwise disregard these prompts. for instance, adaptive prompts could force
students to follow them or explain how the prompted srl processes can improve learning. evaluating such adaptive prompts
fostering srl processes would provide further insights on how
students comply with and benefit from srl prompts.

8. acknowledgments
this publication is based upon work supported by the national
science foundation under grant no. drl-1431552 and the social sciences and humanities research council of canada. any

opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the national science foundation or the
social sciences and humanities research council of canada.

9. references
[1] azevedo, r., harley, j., trevors, g., duffy, m., feyzibehnagh, r., bouchet, f. and landis, r. 2013. using trace
data to examine the complex roles of cognitive, metacognitive, and emotional self-regulatory processes during learning
with multi-agent systems. international handbook of metacognition and learning technologies. springer, 427–449.
[2] azevedo, r., martin, s.a., taub, m., mudrick, n.v., millar,
g.c. and grafsgaard, j.f. 2016. are pedagogical agents’
external regulation effective in fostering learning with intelligent tutoring systems? proceedings of the 13th international conference on intelligent tutoring systems (zagreb,
croatia, 2016). springer, 197–207.
[3] beck, j., chang, k., mostow, j. and corbett, a. 2008. does
help help? introducing the bayesian evaluation and assessment methodology. proceedings on the 9th international
conference on intelligent tutoring systems (montréal, qc,
canada, 2008). springer, 383–394.
[4] bixler, r. and d’mello, s. 2015. automatic gaze-based
detection of mind wandering with metacognitive awareness. proceedings of the 23rd international conference on
user modeling, adaptation and personalization (dublin,
ireland, 2015). springer, 31–43.
[5] bouchet, f., harley, j.m. and azevedo, r. 2016. can adaptive pedagogical agents’ prompting strategies improve students’ learning and self-regulation? proceedings of the
13th international conference on intelligent tutoring systems (zagreb, croatia, 2016). springer, 368–374.
[6] conati, c., jaques, n. and muir, m. 2013. understanding
attention to adaptive hints in educational games: an eyetracking study. international journal of artificial intelligence in education. 23, 1–4 (2013), 136–161.
[7] conati, c. and merten, c. 2007. eye-tracking for user modeling in exploratory learning environments: an empirical
evaluation. know.-based syst. 20, 6 (2007), 557–574.
[8] d’mello, s., olney, a., williams, c. and hays, p. 2012.
gaze tutor: a gaze-reactive intelligent tutoring system. international journal of human-computer studies. 70, 5
(2012), 377–398.
[9] d’mello, s., olney, a., williams, c. and hays, p. 2012.
gaze tutor: a gaze-reactive intelligent tutoring system. international journal of human-computer studies. 70, 5
(2012), 377–398.
[10] graesser, a. and mcnamara, d. 2010. self-regulated learning in learning environments with pedagogical agents that interact in natural language. educational psychologist. 45, 4
(2010), 234–244.
[11] hausmann, r.g. and vanlehn, k. 2007. explaining selfexplaining: a contrast between content and generation. proceedings of the 13th international conference on artificial
intelligence in education (los angeles, ca, usa, 2007).
springer, 417–424.126

[12] heiner, c., beck, j. and mostow, j. 2004. improving the help
selection policy in a reading tutor that listens. proceedings
of the instil/icall symposium on nlp and speech technologies in advanced language learning systems (venice,
italy, 2004), 195–198.
[13] jacobson, m.j. 2008. a design framework for educational
hypermedia systems: theory, research, and learning emerging scientific conceptual perspectives. educational technology research and development. 56, 1 (2008), 5–28.
[14] jaques, n., conati, c., harley, j.m. and azevedo, r. 2014.
predicting affect from gaze data during interaction with an
intelligent tutoring system. proceedings of the 12th international conference on intelligent tutoring systems (honolulu, hi, usa, 2014). springer, 29–38.
[15] kardan, s. and conati, c. 2012. exploring gaze data for
determining user learning with an interactive simulation.
proceedings of the 20th international conference on user
modeling, adaptation, and personalization (montréal, qc,
canada, 2012). springer, 126–138.
[16] kardan, s. and conati, c. 2015. providing adaptive support
in an interactive simulation for learning: an experimental
evaluation. proceedings of the 33rd annual acm conference on human factors in computing systems (seoul,
south korea, 2015). acm, 3671–3680.
[17] lallé, s., taub, m., mudrick, n.v., conati, c. and azevedo,
r. 2017. the impact of student individual differences and
visual attention to pedagogical agents during learning with
metatutor. proceedings of the 18th international conference on artificial intelligence in education (wuhan, china,
2017). springer (to appear).
[18] mcnamara, d.s., boonthum, c., levinstein, i.b. and millis,
k. 2007. evaluating self-explanations in istart: comparing word-based and lsa algorithms. handbook of latent
semantic analysis. psychology press. 227–241.
[19] najar, a.s., mitrovic, a. and mclaren, b.m. 2014. adaptive
support versus alternating worked examples and tutored
problems: which leads to better learning? proceedings of
the 22nd international conference on user modeling, adaptation, and personalization (aalborg, denmark, 2014).
springer, 171–182.

[24] shute, v.j. 2008. focus on formative feedback. review of
educational research. 78, 1 (2008), 153–189.
[25] trevors, g., duffy, m. and azevedo, r. 2014. note-taking
within metatutor: interactions between an intelligent tutoring system and prior knowledge on note-taking and learning.
educational technology research and development. 62, 5
(2014), 507–528.

appendix a
all statistical results for explicit compliance prompts (discussed in
section 6.1). bold indicates a significant effect.
prompt
suggest subgoal
review notes
revise summary
summarizing
move on subgoal
stay on subgoal
open diagram

f value
f1,20 = 11.4
f1,20 = 7.43
f1,20 = 6.17
f1,20 = 1.76
f1,20 = 0.92
f1,20 = 1.47
f1,20 = 0.71

p-value
p=.003
p=.013
p=.02
p=.20
p=.35
p=.24
p=.41

effect size
ηp2=.27
ηp2 =.16
ηp2 =.15
ηp2 =.06
ηp2 =.02
ηp2 =.01
ηp2 =.08

appendix b
all statistical results for explicit compliance prompts (discussed in
section 6.2). bold indicates a significant effect.
prompt
add subgoal
move on
page
stay on
page

measure
window length
#fixations on
page
#srl strategies
window length
#fixations on page
#srl strategies
window length
#fixations on page
#srl strategies

f value

p-value

f1,3 = .91

p = .41

effect
size
ηp2 = .04

f1,3 = 13

p = .03

ηp2 = .29

f1,3 = .02
f1,10 = .00
f1,10 = .03
f1,10 = .40
f1,10 = .34
f1,10 = .07
f1,10 = .004

p = .90
p = .98
p = .86
p = .54
p = .57
p = .79
p = .95

ηp2 = .01
ηp2 = .00
ηp2 = .00
ηp2 = .01
ηp2 = .01
ηp2 = .03
ηp2 = .02

[20] poitras, e.g. and lajoie, s.p. 2014. developing an agentbased adaptive system for scaffolding self-regulated inquiry
learning in history education. educational technology research and development. 62, 3 (2014), 335–366.
[21] ritter, s., anderson, j.r., koedinger, k.r. and corbett, a.
2007. cognitive tutor: applied research in mathematics education. psychonomic bulletin & review. 14, 2 (2007), 249–
255.
[22] roll, i., aleven, v., mclaren, b.m. and koedinger, k.r.
2011. improving students’ help-seeking skills using metacognitive feedback in an intelligent tutoring system. learning and instruction. 21, 2 (2011), 267–280.
[23] roll, i., wiese, e.s., long, y., aleven, v. and koedinger,
k.r. 2014. tutoring self-and co-regulation with intelligent
tutoring systems to help students acquire better learning
skills. design recommendations for intelligent tutoring
systems, volume 2. u.s. army research laboratory. 169–
182.